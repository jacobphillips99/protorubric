scoring_configs:
  - binary
  - unit_scalar
  - assets/examples/example_configs/my_scoring_config.yaml
  - name: overall-quality-scoring-config
    subtype: continuous
    min: 0
    max: 100
  - free_text

aggregator_configs:
  - name: llm-summarizer
    subtype: llm
    model: gpt-4.1
  - assets/examples/example_configs/my_aggregator_config.yaml

evaluator_configs:
  - name: my-sole-llm
    type: llm
    model: gpt-4.1
  - name: my-triple-llm
    type: llm
    model: gpt-4.1-mini
    n_samples: 3
  - assets/examples/example_configs/my_llm_committee_evaluator.yaml

requirements:
  - name: grammar
    query:
      instruction: Is the response grammatically correct?
      scoring_config: binary
    evaluator: my-triple-llm
    aggregator: all

  - name: tone
    query:
      instruction: What tone does the response have?
      scoring_config: tone-scoring-config
    evaluator: my-sole-llm

  - name: job_quality
    query:
      instruction: What is the quality of the idea?
      scoring_config: job-quality-num-scoring-config
    dependency_names:
      - grammar
      - tone
      - helpfulness
    evaluator: my-sole-llm
    aggregator: mean

  - name: overall_quality
    query:
      instruction: What is the overall quality of the job?
      scoring_config: overall-quality-scoring-config
    dependency_names:
      - job_quality
    evaluator: my-sole-llm
    aggregator: median

  - name: helpfulness
    query:
      instruction: Is the response helpful?
      scoring_config: unit_scalar
    evaluator: my-sole-llm

  - name: summarizer
    dependency_names:
      - overall_quality
      - job_quality
      - grammar
      - tone
      - helpfulness
    evaluator: pass-through
    aggregator: llm-summarizer
