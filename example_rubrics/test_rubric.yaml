scoring_configs:
  - binary
  - unit_scalar
  - example_rubrics/my_scoring_config.yaml
  - name: overall_quality
    subtype: continuous
    min: 0
    max: 100

evaluators:
  - name: my-sole-llm
    type: llm
    model: gpt-4.1
  - name: my-triple-llm
    type: llm
    model: gpt-4.1-mini
    n_samples: 3
  - example_rubrics/my_llm_committee_evaluator.yaml

requirements:
  - name: helpfulness
    query:
      instruction: Is the response helpful?
      scoring_config: unit_scalar
    evaluator: my-sole-llm

  - name: grammar
    query:
      instruction: Is the response grammatically correct?
      scoring_config: binary
    evaluator: my-triple-llm
    aggregator: all

  - name: tone
    query:
      instruction: What tone does the response have?
      scoring_config: tone
    evaluator: my-sole-llm

  - name: job_quality
    query:
      instruction: What is the quality of the idea?
      scoring_config: job_quality_num
    evaluator: my-llm-committee
    aggregator: mean

  - name: overall_quality
    query:
      instruction: What is the overall quality of the job?
      scoring_config: overall_quality
    evaluator: my-llm-committee
    aggregator: median
